# Reinforcement Learning

**参考文献**



--------------------------------分割线------------------------------------

## 什么是强化学习

强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法，其不需要同监督学习一样具有标签，也和无监督的聚类降维不同，
它是一个决策过程，强调如何基于环境而行动，以取得最大化的预期期望。
强化学习把学习看作一个试错评价过程，agent选择一个动作用于环境，随之环境状态发生改变，同时给予一个反馈给agent，agent根据反馈和当前状态选择下一步动作，其目标在于使得期望反馈最大化。
其一般被建模为马尔可夫决策过程，包含：环境状态的集合S、动作集合A、状态间转移的规则P、奖励函数R。

## 强化学习中的损失函数

在Policy Gradient中，目标为最大化reward，损失函数为-reward，其值为 likelihood * R的积分， 梯度为-log(likelihood) * R

在Q-Learning中，目标为V(s)和Q(s,a)的评估尽可能准确，基于V(s)或Q(s,a)的MSE，有MC和TD两种方法来计算损失函数

A3C中引入最大熵作为正则项，增大策略的探索能力，而在SAC中则是直接作为最优项

PPO、TRPO中都引入了KL散度来约束学习策略与互动策略之间的距离

## 马尔可夫过程是什么？

马尔可夫假设：随机过程中各个状态St的概率分布仅与它的前一状态St-1有关，P(Xt+1|...Xt-1,Xt-1,Xt) = P(Xt+1|Xt),
（马尔可夫链模型的状态转移矩阵收敛到的稳定概率分布与初始状态概率分布无关，但仅用于非周期的马尔科夫链以及）
符合马尔可夫假设的随机过程称为马尔可夫过程

## MDP（马尔可夫决策过程）是什么？

强化学习中两部分：假设状态转化的马尔可夫性
