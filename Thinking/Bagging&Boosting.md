# Bagging 和 Boosting 区别

**参考文章**

方差和偏好：https://www.zhihu.com/question/27068705

bagging 减少方差 boosting 减少偏好：https://www.zhihu.com/question/26760839

bagging & boosting 区别：https://medium.com/@pkqiang49/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0-%E8%AF%A6%E8%A7%A3-bagging-boosting-%E4%BB%A5%E5%8F%8A%E4%BB%96%E4%BB%AC%E7%9A%84-4-%E7%82%B9%E5%8C%BA%E5%88%AB-6e3c72df05b8

-----------------------------分割线------------------------------------

前提知识：有关模型的varience（方差）和bias（偏好）可看以下的回答（尤其是里面的图，方便理解）：

https://www.zhihu.com/question/27068705

高varience意味着模型预测结果很散，但平均值靠近真实值，意味着过拟合，模型过于复杂。

高bias意味着模型预测结果很集中，但平均值严重偏离真实值，意味着欠拟合，模型过于简单。

上述的模型指不同的数据，同样的算法。高varience为啥过拟合，因为数据稍有不同就会导致预测剧烈变化，高bias为啥为欠拟合，因为无论用什么数据预测都差不多，模型过于简单。

Bagging **放回**抽样，一个模型一票（重要性相同），样本之间没有关联，可**并行**处理，一般情况下**方差更小**，方差更小的原因在于不同模型并不完全相同。

Boosting，每一轮训练集都相同，模型具有**不同的权重**，预测函数只能顺序生成，一般情况下**偏差更小**，其原因在于序列化地不断减小损失函数，同时后面的模型与前面的模型具有高相关性。
